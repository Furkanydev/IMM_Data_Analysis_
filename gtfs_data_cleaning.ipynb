{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9da48b83-c3f3-4ab9-9846-9b3505f82181",
   "metadata": {},
   "source": [
    "Istanbul Public Transportation Data Analysis Codes\n",
    "\n",
    "# Cleaning GTFS data\n",
    "This notebook processes raw stops, routes, trips, and stop_times files. \n",
    "It cleans the text, handles coordinates, and converts time to seconds for analysis.\n",
    "Note: This dataset is publicly available and used for data analysis purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03665e55-73b9-42ab-b943-f3ef73b4c432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Libraries \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Standard helper for text cleaning\n",
    "def clean_text(x):\n",
    "    if pd.isna(x):\n",
    "        return x\n",
    "    return str(x).strip()\n",
    "\n",
    "# Helper function to convert time fields to seconds\n",
    "def time_to_seconds(t):\n",
    "    try:\n",
    "        h, m, s = map(int, t.split(\":\"))\n",
    "        return h * 3600 + m * 60 + s\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "print(\"Setup completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f761aca5-27ca-4947-880d-377ce4c82aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stops Data Preprocessing\n",
    "\n",
    "# 1) Read CSV safely\n",
    "df_stops = pd.read_csv(\"stops.csv\", encoding=\"latin1\", on_bad_lines=\"skip\")\n",
    "\n",
    "# 2) Clean text fields\n",
    "text_cols = [\"stop_id\", \"stop_code\", \"stop_name\", \"stop_desc\"]\n",
    "for col in text_cols:\n",
    "    if col in df_stops.columns:\n",
    "        df_stops[col] = df_stops[col].apply(clean_text)\n",
    "\n",
    "# 3) Drop rows missing mandatory fields & remove duplicates\n",
    "df_stops = df_stops.dropna(subset=[\"stop_id\", \"stop_name\", \"stop_lat\", \"stop_lon\"])\n",
    "df_stops = df_stops.drop_duplicates(subset=[\"stop_id\"])\n",
    "\n",
    "# 4) Standardize location_type and validate coordinates\n",
    "df_stops[\"location_type\"] = df_stops[\"location_type\"].fillna(0).astype(int)\n",
    "df_stops = df_stops[\n",
    "    (df_stops[\"stop_lat\"].between(-90, 90)) & \n",
    "    (df_stops[\"stop_lon\"].between(-180, 180))\n",
    "]\n",
    "\n",
    "# 5) Export cleaned data\n",
    "df_stops.to_csv(\"stops_cleaned.csv\", index=False)\n",
    "print(f\"Stops cleaning completed. Row count: {len(df_stops)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf2bc66-d1e5-4fdb-a51f-d168ee922ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Routes Data Preprocessing\n",
    "\n",
    "df = pd.read_csv(\"routes.csv\")\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# Route validation\n",
    "df[\"route_id\"] = df[\"route_id\"].astype(str)\n",
    "df[\"route_type\"] = df[\"route_type\"].astype(\"category\")\n",
    "\n",
    "text_cols = [\"route_short_name\", \"route_long_name\", \"route_desc\"]\n",
    "for col in text_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "# Drop missing/duplicates\n",
    "df = df.dropna(subset=[\"route_id\", \"route_type\"]).drop_duplicates(subset=[\"route_id\"])\n",
    "\n",
    "# Remove visual columns\n",
    "non_analytic = [\"route_url\", \"route_color\", \"route_text_color\"]\n",
    "df = df.drop(columns=[c for c in non_analytic if c in df.columns])\n",
    "\n",
    "# Save\n",
    "df.to_csv(\"routes_cleaned.csv\", index=False)\n",
    "print(f\"Routes processed. Row count: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23237c52-c115-49a1-9916-a2615f76a111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trips Data Preprocessing\n",
    "\n",
    "df = pd.read_csv(\"trips.csv\")\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# Type casting\n",
    "for col in [\"route_id\", \"service_id\", \"trip_id\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str)\n",
    "\n",
    "if \"direction_id\" in df.columns:\n",
    "    df[\"direction_id\"] = df[\"direction_id\"].astype(\"category\")\n",
    "\n",
    "# Drop invalid records\n",
    "df = df.dropna(subset=[\"trip_id\", \"route_id\"]).drop_duplicates(subset=[\"trip_id\"])\n",
    "\n",
    "# Final cleanup\n",
    "non_essential = [\"wheelchair_accessible\", \"bikes_allowed\"]\n",
    "df = df.drop(columns=[c for c in non_essential if c in df.columns])\n",
    "\n",
    "# Relationship validation (assert)\n",
    "assert df[\"route_id\"].notnull().all()\n",
    "\n",
    "# Save\n",
    "df.to_csv(\"trips_cleaned.csv\", index=False)\n",
    "print(f\"Trips processed. Row count: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e3e7fb-d70e-4c75-ab67-5cc54e21acf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Times Data Preprocessing\n",
    "\n",
    "df = pd.read_csv(\"stop_times.csv\")\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "for col in [\"trip_id\", \"stop_id\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str)\n",
    "\n",
    "df[\"stop_sequence\"] = pd.to_numeric(df[\"stop_sequence\"], errors=\"coerce\")\n",
    "\n",
    "# Time conversion and segment travel time\n",
    "time_cols = [\"arrival_time\", \"departure_time\"]\n",
    "for col in time_cols:\n",
    "    if col in df.columns:\n",
    "        df[f\"{col}_sec\"] = df[col].astype(str).apply(time_to_seconds)\n",
    "\n",
    "df[\"segment_travel_time\"] = df[\"departure_time_sec\"] - df[\"arrival_time_sec\"]\n",
    "df.loc[df[\"segment_travel_time\"] < 0, \"segment_travel_time\"] = None\n",
    "\n",
    "# Mandatory cleanup\n",
    "df = df.dropna(subset=[\"trip_id\", \"stop_id\", \"stop_sequence\"])\n",
    "df = df.drop_duplicates(subset=[\"trip_id\", \"stop_sequence\"])\n",
    "\n",
    "# Drop original time strings\n",
    "df = df.drop(columns=[c for c in time_cols if c in df.columns])\n",
    "\n",
    "# Save\n",
    "df.to_csv(\"stop_times_cleaned.csv\", index=False)\n",
    "print(f\"Stop Times processed. Row count: {len(df)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
